{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"WVcdaipdmw2M","executionInfo":{"status":"ok","timestamp":1726922273445,"user_tz":-480,"elapsed":1054845,"user":{"displayName":"P. Zheng","userId":"08572117504573477537"}},"outputId":"76035da1-f88c-4d98-ef7d-79d3c9423f83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/rwalk/gsdmm.git\n","  Cloning https://github.com/rwalk/gsdmm.git to /tmp/pip-req-build-_8m6w2ff\n","  Running command git clone --filter=blob:none --quiet https://github.com/rwalk/gsdmm.git /tmp/pip-req-build-_8m6w2ff\n","  Resolved https://github.com/rwalk/gsdmm.git to commit 4ad1b6b6976743681ee4976b4573463d359214ee\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gsdmm==0.1) (1.26.4)\n","Building wheels for collected packages: gsdmm\n","  Building wheel for gsdmm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gsdmm: filename=gsdmm-0.1-py3-none-any.whl size=4586 sha256=a167f6a4b062b848b85353d4c917824011f94c89494b59bd2da8049e443324a9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-d3x2cegr/wheels/da/d3/6e/a612d7cff0fcfb6470b8c113fc04931ecffb466ac19b9c5f3c\n","Successfully built gsdmm\n","Installing collected packages: gsdmm\n","Successfully installed gsdmm-0.1\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n","Collecting pyLDAvis\n","  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.1.4)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n","Collecting funcy (from pyLDAvis)\n","  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (10.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.7.1)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.1.4)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n","Installing collected packages: funcy, pyLDAvis\n","Successfully installed funcy-2.0 pyLDAvis-3.4.1\n","Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-26-24] vedal987.csv\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:updated prior is not positive\n"]},{"output_type":"stream","name":"stdout","text":["\n","Topic 0: Sample Messages for Review\n","huh right\n","caught\n","kekw mean\n","mood right\n","thanks\n","\n","Topic 1: Sample Messages for Review\n","ctrl\n","roman empire\n","clock dummy\n","monster\n","modcheck\n","\n","Topic 2: Sample Messages for Review\n","crnkek\n","hallelujah210 maya601 mod power\n","shame\n","fuck\n","prefer love evil\n","\n","Topic 3: Sample Messages for Review\n","gura\n","evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm evilcry edm\n","thanks vedalheart love\n","know\n","cat eat day\n","\n","Topic 4: Sample Messages for Review\n","vedal mosquito\n","fine\n","wayyy\n","nope\n","grass\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a49ddee3-b78b-472a-9d2c-c8715efef25a\", \"cleaned_anonymized_[3-26-24] vedal987.csv_report.pdf\", 661577)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[1-5-24] vedal987.csv\n","\n","Topic 0: Sample Messages for Review\n","time call narrator vedal\n","stay catkiss stay catkiss stay catkiss stay catkiss stay catkiss\n","reallygunpull smadge reallygunpull smadge reallygunpull smadge reallygunpull smadge reallygunpull smadge reallygunpull smadge\n","bedge stream\n","vedal icant\n","\n","Topic 1: Sample Messages for Review\n","see\n","rizzdal rizzdal\n","hear click\n","dinodance singsnote dinodance singsnote dinodance\n","watch stream\n","\n","Topic 2: Sample Messages for Review\n","wishlist\n","pointless\n","trust\n","copium\n","sleepy\n","\n","Topic 3: Sample Messages for Review\n","manage\n","fix gigavedal oshi fix gigavedal oshi fix gigavedal oshi fix gigavedal oshi fix gigavedal oshi fix gigavedal oshi fix gigavedal oshi fix gigavedal\n","corpa\n","copium\n","need\n","\n","Topic 4: Sample Messages for Review\n","corpa\n","corpa\n","chickenpizzasteak sub gellatingel\n","chickenpizzasteak sub randomevilact\n","skip skip skip skip skip\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ff920836-0800-4e82-8f56-875f0eb0a7b8\", \"cleaned_anonymized_[1-5-24] vedal987.csv_report.pdf\", 481472)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[2-3-24] AI_RacingTV.csv\n","\n","Topic 10: Sample Messages for Review\n","cyrenevr random car\n","cyrenevr random car\n","cyrenevr gt500 super\n","cyrenevr random car\n","cyrenevr dodge challenger hellcat\n","\n","Topic 0: Sample Messages for Review\n","garage type car fiat acr street car falcon vintage street car\n","garage type car falcon vintage street car acr street car\n","falcon\n","falcon vintage street car\n","waynetrain94 falcon gtho car\n","\n","Topic 15: Sample Messages for Review\n","hugrd03 pantera gts\n","garage type car fiat acr street car falcon vintage street car\n","garage type car jordan blind random oreca acura jordan ej10\n","p201 type garage look\n","mercury cougar random type garage look\n","\n","Topic 3: Sample Messages for Review\n","pot amalgyte win robokop6000sux win\n","pot\n","wowkcb mondeo\n","pot zygote22 win\n","pot suzannegreenberg win\n","\n","Topic 4: Sample Messages for Review\n","waynetrain94 porsche carrera\n","waynetrain94 f50\n","waynetrain94 random car\n","waynetrain94 lm\n","waynetrain94 car\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_60432926-db1a-4955-8ea4-759482eb8a24\", \"cleaned_anonymized_[2-3-24] AI_RacingTV.csv_report.pdf\", 766058)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-31-24] AI_RacingTV.csv\n","\n","Topic 9: Sample Messages for Review\n","\n","Topic 8: Sample Messages for Review\n","\n","Topic 14: Sample Messages for Review\n","\n","Topic 5: Sample Messages for Review\n","\n","Topic 0: Sample Messages for Review\n","texas_rangerswot driving\n","st4n_bzh flm09\n","st4n_bzh lamborghini murcielago\n","st4n_bzh camaro\n","st4n_bzh driving\n","Error in pyLDAvis visualization: Object of type complex is not JSON serializable\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1c9d51a1-8024-4c59-b991-dae7336b5c88\", \"cleaned_anonymized_[3-31-24] AI_RacingTV.csv_report.pdf\", 759564)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-21-24] TrumpOrBiden2024.csv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gensim/models/ldamodel.py:847: RuntimeWarning: divide by zero encountered in scalar divide\n","  perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Topic 8: Sample Messages for Review\n","fun talk poop eating\n","chess poop wanna play\n","biden mouth\n","trump athene sort thing poop poop trump poop bit byte screw nut rainsins\n","hole mouth rubber dingdong\n","\n","Topic 4: Sample Messages for Review\n","president hop gon lot fun\n","voting election\n","donald peek gon world peace day\n","trump gon wall moon\n","sleepy gon empire propaganda uranus homelander dildo\n","\n","Topic 10: Sample Messages for Review\n","trump dinner time checkmate\n","duck wife past time\n","trump demand tragedy deal cum riot time cum mother\n","queeniechaos talk way cat type trunanashabidaprzure\n","talk person lol\n","\n","Topic 3: Sample Messages for Review\n","news flash twitch cumrag\n","lot question\n","ferabeast link goodbye stop spamming wordsphrases\n","trump viewer stop twitch ai nt shit\n","sleepy stop burn moon\n","\n","Topic 16: Sample Messages for Review\n","tender crack addict biden trump maga hat\n","address room catboy shortage japanesecatgirls\n","news flash japanesecatgirls twump doangbeetle way\n","room turn\n","news flash japanesecatgirls twump doangbeetle way\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6f3b712a-a17b-4f99-a724-52f387281111\", \"cleaned_anonymized_[3-21-24] TrumpOrBiden2024.csv_report.pdf\", 480294)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-31-24] TrumpOrBiden2024.csv\n","\n","Topic 0: Sample Messages for Review\n","trump stuff chimpanzee\n","opinion allegation diddy\n","president voice attitude science\n","voice playht voice generator voice check section stream click link httpsplayht\n","trump hope biden empire strike maga trump\n","\n","Topic 10: Sample Messages for Review\n","mixture pointy pleasure godzilla stool week crack happiness\n","president know day\n","explain grab someone cookis caveman speak\n","guy friend hate\n","wall pile car\n","\n","Topic 3: Sample Messages for Review\n","foot picture\n","rp4agudtyme ill gatekeeper\n","show probers le body\n","look blue\n","trump kfc bucket body cavity mouth\n","\n","Topic 4: Sample Messages for Review\n","subscribe fuel debate unlock httpswwwtwitchtvtrumporbiden2024subscribe\n","stream httpswwwredditcomraistreamfail\n","subscribe fuel debate unlock httpswwwtwitchtvtrumporbiden2024subscribe\n","sorry want make feel\n","stream httpswwwredditcomraistreamfail\n","\n","Topic 2: Sample Messages for Review\n","sub trumpo1baby trumpo1scammer trumpo1wall trumpo1boom trumpo1cookie trumpo1rekt trumpo1nuke\n","beat box trump\n","eaton_snatch gift sub channel\n","hotdog trump eat\n","sub trumpo1baby trumpo1scammer trumpo1wall trumpo1boom trumpo1cookie trumpo1rekt trumpo1nuke\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f5a1cd41-8a62-4306-86e3-65d0a463fba1\", \"cleaned_anonymized_[3-31-24] TrumpOrBiden2024.csv_report.pdf\", 528638)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[4-1-24] AtheneAIHeroes.csv\n","\n","Topic 7: Sample Messages for Review\n","tell time dimension space box fit pool library toilet\n","sauce elevator tip lamb sauce safety\n","joke line b1rs b1rs b1rb1rs b1r b1rs str8 b1rs sideways b1rs b1rs space b1rs stick b1rs b1rs b1rs b1r b1r b1rs\n","chicken nuggies gimme chicken nuggies chicken nuggies phat floor nuggies nuggies nuggies b1r\n","athene chat\n","\n","Topic 8: Sample Messages for Review\n","doctor giant junk check\n","story synphage greedythagoon synphage man greedythagoon hello name montoya b1r prepare cry\n","synphage\n","pausechamp friend\n","voice playht voice generator voice check section stream click link httpsplayht\n","\n","Topic 2: Sample Messages for Review\n","pant\n","trainwrecks cart agent lot dude\n","time laforge cook food try bird meat troi environment commander bit conform commander riker\n","kid\n","heard snoop dis track poop fight cheese\n","\n","Topic 1: Sample Messages for Review\n","gon phucking gon trash light scene phucking time guy guy cut set man\n","crazyaboutyou11 time lamb sauce\n","lol lul\n","bill recipe gordon impersonation donut\n","story time poosee story word\n","\n","Topic 0: Sample Messages for Review\n","please way tax torsion help sentence thanks\n","yes ooo yes booboobubooboobooboobooboboobbooobooboobooboobooboobooboobooboobooboobuboob pause take trump\n","tell light saber year war star tell people terminator\n","gamers cod get hell guy damn shotgun shoot point check scope skill hey mom mountain dew gee scope scrub hold mom please mountain dew god bidch bidch hate bidch\n","arnold hey creature yes name mind get mar hell fuhcker toilet hole\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f321c547-ccff-418e-a8f3-4d774858ce64\", \"cleaned_anonymized_[4-1-24] AtheneAIHeroes.csv_report.pdf\", 770062)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-21-24] AtheneAIHeroes.csv\n","\n","Topic 0: Sample Messages for Review\n","story\n","ramp frog throat word ground beef word\n","join globalists look jawline\n","opinion movie\n","ummm humm okay phuck ill thing suck bill thanks album\n","\n","Topic 1: Sample Messages for Review\n","lmao\n","discord\n","march deed chain ignorance path truth heart justice tall flame path equality voice spread\n","turner tretment\n","burr billyy billyboi bald please hamlet backwards language uhohihahuhohihahah\n","\n","Topic 2: Sample Messages for Review\n","pitch series doctor character time\n","case\n","tyler1 tell living\n","people street road saggystreet live\n","speedos seashark\n","\n","Topic 3: Sample Messages for Review\n","immortality lolol\n","butt pucker state plan doodoo ahahahahahaha\n","world order mean shark pronounciation world orderlolojolorderlor\n","pokémon hunt plan ruby let scarlet violet\n","heart infowar alexjones everyones gubbment document take nutslapping supplement bidch shop discount code b1r percent male curvature supply angle war mind\n","\n","Topic 4: Sample Messages for Review\n","b1r surprise dish expert prepare start love dumpster fire aaaaaaaaaaaaaaaaaaaaaaaaaaaaaah motor oil nugget biscuit nugget biscuit nugget biscuit nugget biscuit nugget biscuit\n","b1rs cute omg hand look hehe b1rkun see meワ thing sperhmsama work hard๑ㅁ๑ sperhmsama meet ﾉヮﾉ ﾟheheheb1rkun moist\n","trump batch phart jar phart jar lord god smell gon schitt come\n","movie zack snyders edition right\n","world thing interesting\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9f9f7cb0-0e8d-43d8-88cc-8f8bfba6af45\", \"cleaned_anonymized_[3-21-24] AtheneAIHeroes.csv_report.pdf\", 721550)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[2-29-24] AiTelevision.csv\n","\n","Topic 0: Sample Messages for Review\n","emo goth reveals earth\n","aitelevision request analysis\n","stash\n","analysis\n","request analysis\n","\n","Topic 1: Sample Messages for Review\n","story replaces morty awe power show share advice morty cope\n","video speculum catch question morty beth question question question describes detail length size texture std\n","toilet song play backgroundmg milk sunsetory milk sunset\n","cyberpunk light britt style portrait photo cyborg robot chemical laboratory face face star painting artstation focus illustration art otomo katsuhiro shirō masamune oshii mamoru\n","channel point drunk call police\n","\n","Topic 2: Sample Messages for Review\n","request analysis violence\n","encounter jasontheartist check masterpiece\n","story episode show hell host chef character tvmoviesnovelsvideogameshistoryanime character description ingredient struggle kitchen judge dish chef episode\n","request analysis violence\n","request analysis hate harassmentthreatening violence\n","\n","Topic 3: Sample Messages for Review\n","morty waifu character art kazenoko girl art art redjuice seed389110432\n","story episode show hell host chef character tvmoviesnovelsvideogameshistoryanime character description ingredient struggle kitchen judge dish chef episode\n","story judge audition character tvfilmsnovelsvideogameshistoryanime character becomepornstars state theirporn position sound turn episode\n","judge competition food network unique dish obscure cartoon character character video game character personality figure contestant state ingredient detail episode\n","government flag attack gain approval\n","\n","Topic 4: Sample Messages for Review\n","government flag attack gain approval\n","type img image description story story video video description svideo story video image httpsdiscordggb3jsxhjnet reset minute youtube httpswwwyoutubecomplaylistlistpldnq2lbrvoaltduyrtpidhicqleaf5cfn\n","type img image description story story video video description svideo story video image httpsdiscordggb3jsxhjnet reset minute youtube httpswwwyoutubecomplaylistlistpldnq2lbrvoaltduyrtpidhicqleaf5cfn\n","type img image description story story video video description svideo story video image httpsdiscordggb3jsxhjnet reset minute youtube httpswwwyoutubecomplaylistlistpldnq2lbrvoaltduyrtpidhicqleaf5cfn\n","mustache\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9c0b4898-e061-4efe-9e32-32e59dcd79ef\", \"cleaned_anonymized_[2-29-24] AiTelevision.csv_report.pdf\", 655961)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[2-9-24] AiTelevision.csv\n","\n","Topic 0: Sample Messages for Review\n","comedy roast stephen repeat joke roaster roaster use language roaster scientist end stephen roast partipants\n","story morty topic legit analysis question foot morty bringing counter argument counterpoint efficiency end source witness\n","svideo summer living whisk decides explanationlecture explanationlecture hev suit dangerhazards family member counter argument dialogue\n","reset story video svideo save imageq queue httpsdiscordggb3jsxhjnet youtube httpswwwyoutubecomplaylistlistpldnq2lbrvoaltduyrtpidhicqleaf5cfn\n","story img benjaminamoryjasontheartistjasontheartistjasontheartistjasontheartist video queue jasontheartist\n","\n","Topic 1: Sample Messages for Review\n","folk context demographic\n","y mod rule wonit\n","analysis\n","analysis violence\n","request analysis violence\n","\n","Topic 2: Sample Messages for Review\n","svideo summer land top sweaty man plummet stanky gaping describe detail family escape wildlifeinhabitants action scene clever dialoguewriting epic end\n","img summer search history morty point thensfw mlp fanfics state perverse result family morty cry\n","story summer living whisk decides explanationlecture explanationlecture hair family member counter argument dialogue\n","argument\n","story meet court talk phphphphphphphphphphphphphph\n","\n","Topic 3: Sample Messages for Review\n","morty ylvis fox fox pooperhole line remain emotion lyrics_line format loud dialogue\n","svideo hold party play game reallife celebrity figure list dimension detail state dimension letter point get dimension complain vivid detail\n","hide context\n","story episode line game play scene suggestion scene style response suggestion character announces show pointless prize\n","video decapitate morty pas blender\n","\n","Topic 4: Sample Messages for Review\n","blonky zone\n","whew\n","adventure\n","check knowyourmeme\n","svideo introduce family start find memory parasite accuse reference episode rickall morty show story scene clever end\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_680b81d3-3974-4120-bb50-c605f7312968\", \"cleaned_anonymized_[2-9-24] AiTelevision.csv_report.pdf\", 613192)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-31-24] ask_jesus.csv\n","\n","Topic 4: Sample Messages for Review\n","feel beer stream\n","right\n","chief sorry bother stream chance wine recipe please water thank love heyguys heyguys\n","stop posting link warning\n","apply moderator stream fill application form httpsformsgle3qujcwhywnbthn866\n","\n","Topic 12: Sample Messages for Review\n","stop spamming wordsphrases\n","holy day reception room mad methane pig factory realitybit tha sanhedrin\n","death day\n","_ fur kitty sleepy purr\n","lunch stop bath room eat wherever eat taco supremes let food peace\n","\n","Topic 8: Sample Messages for Review\n","thing world\n","hate people hate\n","hair advice look cool\n","thing\n","opinion skunk ape please brain cracker\n","\n","Topic 6: Sample Messages for Review\n","chat\n","chat\n","chat\n","name soda name end name please wow way understand\n","night lord hope joy sinner chat\n","\n","Topic 5: Sample Messages for Review\n","story adam style\n","childrens story easter bunny\n","blasphemy lord savior\n","i arm space story noah way please use replacement panenka please amen lord siuuuuu\n","please friend time story aeiou pikacu\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_4e5316d4-412f-4f45-b0be-9ab9ae454ed9\", \"cleaned_anonymized_[3-31-24] ask_jesus.csv_report.pdf\", 596534)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing file: /content/drive/My Drive/Twitch dataset/Cleaned data/cleaned_anonymized_[3-21-24] ask_jesus.csv\n","\n","Topic 11: Sample Messages for Review\n","game god name\n","bit\n","hope answer mine\n","pizzeria thing wheelchair please explain work\n","mean truth hear answer\n","\n","Topic 5: Sample Messages for Review\n","czechia thing ask geography teacher year thanks bee\n","ask riddle sphinx tell thank\n","church business vendor overcharge jewelry table guard mad\n","brother people death experience body experience think\n","room memory need code word ooga booga ooga googa\n","\n","Topic 3: Sample Messages for Review\n","friend please space eehhhooflets_gooo brain polyp god rest ramen\n","explain support nonprofit project athene maker man\n","hey thanks story life story brain polyp understand hey\n","eat hamburger man word reply letter word ham rest word gur\n","jeucy please ghost please space shshshshshshsh response heart kumbaya\n","\n","Topic 4: Sample Messages for Review\n","ghost please ghost please space aaghtaaaoogogoadsh response heart ramen jesua\n","ramen brother\n","question jesus start message question\n","story need abooboo brain way thank ramen\n","brrrrrr ramen\n","\n","Topic 7: Sample Messages for Review\n","god exists time space clarification answer explain confines language answer use hand trick\n","god name space word ooooooooooooooo please skip preamble\n","explain force path follow\n","proof god pls\n","support satan\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e0253559-e5a3-4f35-804c-011cf19f7226\", \"cleaned_anonymized_[3-21-24] ask_jesus.csv_report.pdf\", 562928)"]},"metadata":{}}],"source":["!pip install git+https://github.com/rwalk/gsdmm.git\n","!pip install nltk spacy gensim pyLDAvis networkx wordcloud\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import re\n","import random\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk import pos_tag\n","import nltk\n","import spacy\n","import gensim\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","import pyLDAvis\n","import pyLDAvis.gensim_models as gensimvis\n","import networkx as nx\n","from collections import Counter\n","from itertools import combinations\n","from matplotlib.backends.backend_pdf import PdfPages\n","\n","# Load Spacy's English model for Named Entity Recognition\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Mount Google Drive to access the dataset stored there\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Download necessary NLTK resources for tokenization and POS tagging\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","\n","general_stopwords = {\n","    'would', 'could', 'should', 'might', 'must', 'will', 'shall', 'can', 'may', 'wouldn', 'couldn', 'shouldn',\n","    'mightn', 'mustn', 'won', 'shan', 'can', 'mayn', 'just', 'don', 'didn', 'doesn', 'aren', 'isn', 'wasn',\n","    'weren', 'hasn', 'haven', 'hadn', 'does', 'did', 'don', 'does', 'did', 'don', 'now', 'then', 'once',\n","    'after', 'before', 'since', 'during', 'while', 'until', 'ago', 'yet', 'still', 'even', 'ever', 'always',\n","    'never', 'sometimes', 'often', 'usually', 'again', 'too', 'also', 'only', 'really', 'very', 'much',\n","    'more', 'most', 'many', 'several', 'few', 'some', 'any', 'each', 'every', 'all', 'both', 'either',\n","    'neither', 'anyone', 'everyone', 'someone', 'nobody', 'noone', 'nothing', 'anything', 'something',\n","    'everything', 'another', 'such', 'one', 'two', 'three', 'first', 'second', 'third', 'next', 'last',\n","    'same', 'other', 'different', 'new', 'old', 'young', 'long', 'short', 'high', 'low', 'large', 'small'\n","}\n","\n","# Combine all sets of stop words\n","stop_words = set(stopwords.words('english')) | general_stopwords\n","\n","# Define the preprocessing function\n","def preprocess(text):\n","    lemmatizer = WordNetLemmatizer()\n","    # Remove all non-word characters and lower the text\n","    text = re.sub(r'[^\\w\\s]', '', text.lower())\n","    # Split text into tokens\n","    tokens = text.split()\n","    # Lemmatize tokens and remove stop words and short words\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2]\n","    # Apply NER to remove usernames and named entities\n","    doc = nlp(' '.join(tokens))\n","    tokens = [token.text for token in doc if not token.ent_type_]\n","    # Retain only nouns as they are significant for topic identification\n","    nouns = [word for word, pos in pos_tag(tokens) if pos.startswith('NN')]\n","    return nouns\n","\n","# Function to load and preprocess data from CSV files\n","def load_data(file_path):\n","    df = pd.read_csv(file_path)\n","    df['preprocessed'] = df['Message'].apply(preprocess)\n","    return df['preprocessed'].tolist()\n","\n","# Path to the folder containing the dataset\n","folder_path = '/content/drive/My Drive/Twitch dataset/Cleaned data/'\n","file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n","\n","# Function to evaluate coherence\n","def evaluate_coherence(dictionary, docs, limit, start=2, step=3):\n","    coherence_values = []\n","    model_list = []\n","    for num_topics in range(start, limit, step):\n","        model = gensim.models.ldamodel.LdaModel(corpus=[dictionary.doc2bow(doc) for doc in docs],\n","                                                id2word=dictionary,\n","                                                num_topics=num_topics,\n","                                                random_state=100,\n","                                                update_every=1,\n","                                                chunksize=100,\n","                                                passes=10,\n","                                                alpha='auto',\n","                                                per_word_topics=True)\n","        model_list.append(model)\n","        coherencemodel = gensim.models.CoherenceModel(model=model, texts=docs, dictionary=dictionary, coherence='c_v')\n","        coherence_values.append(coherencemodel.get_coherence())\n","    return model_list, coherence_values\n","\n","# Function to randomly select messages from each topic for manual review\n","def random_message_selection(docs, best_model, dictionary, num_samples=5):\n","    topics = best_model.show_topics(num_words=10, formatted=False)\n","    for topic_id, _ in topics[:5]:  # Limit to top 5 topics\n","        topic_docs = [doc for doc in docs if any(topic_id == topic[0] for topic in best_model.get_document_topics(dictionary.doc2bow(doc), minimum_probability=0.1))]\n","        sampled_messages = random.sample(topic_docs, min(len(topic_docs), num_samples))\n","        print(f\"\\nTopic {topic_id}: Sample Messages for Review\")\n","        for message in sampled_messages:\n","            print(' '.join(message))\n","\n","# Function to save plots to a PDF\n","def save_plots_to_pdf(file_path, best_model, dictionary, top_clusters):\n","    pdf_file_name = f'{os.path.basename(file_path)}_report.pdf'\n","    with PdfPages(pdf_file_name) as pdf:\n","        for topic_id in top_clusters:\n","            # Word cloud\n","            topic_words = dict(best_model.show_topic(topic_id, topn=50))\n","            wordcloud = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(topic_words)\n","            plt.figure(figsize=(10, 5))\n","            plt.imshow(wordcloud, interpolation='bilinear')\n","            plt.title(f\"Topic {topic_id} Word Cloud for {os.path.basename(file_path)}\")\n","            plt.axis(\"off\")\n","            pdf.savefig()\n","            plt.close()\n","\n","            # Bar chart\n","            sorted_topic_words = dict(sorted(topic_words.items(), key=lambda item: item[1], reverse=True)[:10])\n","            plt.figure(figsize=(10, 5))\n","            plt.bar(sorted_topic_words.keys(), sorted_topic_words.values())\n","            plt.title(f\"Top Words in Topic {topic_id}\")\n","            plt.xticks(rotation=45)\n","            pdf.savefig()\n","            plt.close()\n","\n","            # Network graph\n","            words = list(sorted_topic_words.keys())\n","            word_pairs = list(combinations(words, 2))\n","            G = nx.Graph()\n","            G.add_edges_from(word_pairs)\n","            pos = nx.spring_layout(G)\n","            plt.figure(figsize=(10, 5))\n","            nx.draw(G, pos, with_labels=True, node_size=50, font_size=10, edge_color='grey')\n","            plt.title(f\"Word Co-occurrence Network for Topic {topic_id}\")\n","            pdf.savefig()\n","            plt.close()\n","\n","    return pdf_file_name\n","\n","# Process each file, perform topic modeling, and generate visualizations\n","for file_path in file_paths:\n","    print(f\"Processing file: {file_path}\")\n","    docs = load_data(file_path)\n","    # Remove any empty documents resulting from preprocessing\n","    docs = [doc for doc in docs if doc]\n","\n","    if len(docs) > 0:\n","        # Create a dictionary of all words in documents\n","        dictionary = gensim.corpora.Dictionary(docs)\n","        # Remove extremes to focus on relevant words only\n","        dictionary.filter_extremes(no_below=10, no_above=0.5, keep_n=10000)\n","        vocab_length = len(dictionary)\n","\n","        if vocab_length == 0:\n","            print(\"No vocabulary available after filtering extremes. Skipping.\")\n","            continue\n","\n","        # Evaluate coherence for different number of topics\n","        model_list, coherence_values = evaluate_coherence(dictionary, docs, limit=20)  # Increase to explore more topics\n","\n","        # Select the model with the highest coherence\n","        best_model_index = coherence_values.index(max(coherence_values))\n","        best_model = model_list[best_model_index]\n","\n","        # Random message selection for validation\n","        random_message_selection(docs, best_model, dictionary)\n","\n","        # Visualize the topics using pyLDAvis\n","        try:\n","            lda_display = gensimvis.prepare(best_model, [dictionary.doc2bow(doc) for doc in docs], dictionary)\n","            pyLDAvis.display(lda_display)\n","        except Exception as e:\n","            print(f\"Error in pyLDAvis visualization: {e}\")\n","\n","        # Generate and display word clouds for each of the top 5 topics\n","        sorted_clusters = sorted(range(best_model.num_topics), key=lambda k: sum([tup[1] for tup in best_model.get_topic_terms(k)]), reverse=True)\n","        top_clusters = sorted_clusters[:5]\n","\n","        # Save plots to PDF\n","        pdf_file_name = save_plots_to_pdf(file_path, best_model, dictionary, top_clusters)\n","\n","        # Provide a download link for the PDF file\n","        from google.colab import files\n","        files.download(pdf_file_name)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1gpCdzUBVAj_5AL6FgLuEQUbbsqILeqfL","timestamp":1719281090288},{"file_id":"15UZTlV4gsVsWUXQya2WX-mze_4hReEJq","timestamp":1719199539796},{"file_id":"1UdquvvoHdUVzngZ28AiEhiGWx8_2o3ot","timestamp":1719199409797},{"file_id":"1VLhZV2sFW74CYtwn69AQMbr3_YLPo0Y0","timestamp":1718895132889},{"file_id":"1Bh0HDMF8ZQ_g7kLYeDNkj-fUKM_xdNLT","timestamp":1718892553507},{"file_id":"1RsqDA8cwPvR3OL-0y3SC5TqOjFo-9jWZ","timestamp":1718065641092},{"file_id":"19OqztM7fQk-v_gqRMYsg-Ukc7lDMRZDn","timestamp":1717756029481},{"file_id":"1ek0mOFIw9q-kjfEKMajqtJW4aSvc1fCO","timestamp":1716801897822},{"file_id":"1f76zgQRHexaJ_-PpCKy738EGGovwXXl4","timestamp":1716242565360},{"file_id":"1JityMIM3UOpBL_DOPOFT3wOALMahhu6w","timestamp":1716238257258},{"file_id":"1YsBuErRqAjoWhDGj89Bt_KIjxeaDgVwM","timestamp":1714138761396},{"file_id":"1fiFhZtpqaOFhxxPJ0mkuu4xC9e_PCjAD","timestamp":1713823781944},{"file_id":"1YHTYFFzjyHHDUa28QvbKg0u1ecE0YFvU","timestamp":1713822045554},{"file_id":"1hphNrR393EQIib44_VspqKJy2MLPQhlZ","timestamp":1713821029465},{"file_id":"1TGcNhpyl6h5Tqhl6Dxis-dGyxOKllPjR","timestamp":1713274950388},{"file_id":"1tEZ5i5C9LAXenvpWOzApobMrn9u01hAT","timestamp":1712788945026},{"file_id":"1GYvnuvBGpY_VKbxPMvx4o_ufreub5jSh","timestamp":1712788076006},{"file_id":"13c7jdPO1fMBoSvL3g0efqSpAlb3rQawx","timestamp":1712786634517}],"authorship_tag":"ABX9TyMGNViNSI7p7mMw0kwW6RdG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}